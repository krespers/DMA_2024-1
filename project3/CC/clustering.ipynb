{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PJ3 Part2 - Clutering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you dont have any packages run this cell\n",
    "\n",
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install yellowbrick\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package import\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load\n",
    "categories = ['algebraic geometry', 'computer vision', 'general economics', 'quantitative biology', 'quantum physics','statistics theory']\n",
    "data = load_files(container_path=r\"text_all\", categories=categories, shuffle=True, encoding='utf-8', decode_error='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Data preprocessing and clustering\n",
    "'''\n",
    "After appropriate data preprocessing, proceed with K-means clustering.\n",
    "Calculate the V-measure score.\n",
    "'''\n",
    "count_vect = CountVectorizer(stop_words='english', max_features=2000, min_df=3, max_df=0.4)\n",
    "data_counts = count_vect.fit_transform(data.data)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "data_trans = tfidf_transformer.fit_transform(data_counts)\n",
    "\n",
    "# V-measure \n",
    "clst = KMeans(n_clusters=6, n_init=10, init='k-means++', random_state=42)\n",
    "clst.fit(data_trans)\n",
    "v_measure = metrics.v_measure_score(data.target, clst.labels_)\n",
    "\n",
    "print(f\"V-measure score: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Find the appropriate number of clusters\n",
    "model = KMeans(init='k-means++', random_state=42)\n",
    "visualizer = KElbowVisualizer(model, k=(2, 12), timings=False)\n",
    "\n",
    "visualizer.fit(data_trans.toarray()) #Fit the data to the visualizer\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization example\n",
    "\n",
    "- data_trans를 올바르게 작성했을 경우 시각화 코드가 실행되게끔 작성 하였음\n",
    "- 보고서 및 발표자료 작성 시 활용할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is defined as an orthogonal linear transformation that transforms the data to a new coordinate system such that the greatest variance by some scalar projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.[12]\n",
    "\n",
    "reference : \n",
    "\n",
    "- [12] : Jolliffe, I. T. (2002). Principal Component Analysis. Springer Series in Statistics. New York: Springer-Verlag. doi:10.1007/b98835. ISBN 978-0-387-95442-4.\n",
    "- [13] : https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA를 사용한 차원 축소\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(data_trans.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering visualization\n",
    "labels = clst.labels_\n",
    "\n",
    "# 클러스터링 결과 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', marker='o')\n",
    "plt.title('K-Means Clustering with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "labels = clst.labels_\n",
    "\n",
    "# Creating a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plotting the data points\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=labels, s=15, cmap='viridis', marker='o')\n",
    "\n",
    "# Setting labels\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "\n",
    "# Title\n",
    "ax.set_title('3D PCA Plot')\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE : \n",
    "\n",
    "Idea \n",
    "- 원본 차원의 데이터를 가우시안 분포를 이용해 유사도 계산\n",
    "- 2차원 평면에 random mapping 후 원 데이터의 유사도와 같아지도록 학습(Minimize KL-Divergence)\n",
    "\n",
    "Definition\n",
    "- 입력 객체(고차원)들의 쌍으로 이루어진 유사성을 측정하는 분포\n",
    "- 저차원 점들의 쌍으로 유사성을 측정하는 분포\n",
    "\n",
    "reference\n",
    "- https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=50).fit_transform(data_trans.toarray())\n",
    "#Clustering visualization\n",
    "labels = clst.labels_\n",
    "\n",
    "# 클러스터링 결과 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=labels, cmap='viridis', marker='o')\n",
    "plt.title('K-Means Clustering with T-SNE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "labels = clst.labels_\n",
    "X_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=50).fit_transform(data_trans.toarray())\n",
    "#Clustering visualization\n",
    "labels = clst.labels_\n",
    "\n",
    "# Creating a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plotting the data points\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], X_embedded[:, 2], c=labels, s=10, cmap='viridis', marker='o')\n",
    "\n",
    "\n",
    "# Title\n",
    "ax.set_title('3D T-SNE Plot')\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
